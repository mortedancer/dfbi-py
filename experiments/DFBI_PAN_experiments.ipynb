{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DFBI PAN Experiments (Grid & Visualization)\n",
    "\n",
    "This notebook runs a parameter sweep on a prepared PAN-like corpus and visualizes results.\n",
    "Expected corpus layout: `corpus_root/author/*.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dfbi.bench import load_folder_corpus, run_grid\n",
    "\n",
    "# === Configure here ===\n",
    "corpus_root = Path('./bench/mini_corpus')  # CHANGE to your PAN corpus, e.g., Path('./corpus_pan12')\n",
    "alphabet    = 'en'                          # 'en' for PAN in English (if using Russian text, set 'ru')\n",
    "horizons    = [1,2,3,4,5,6]\n",
    "metrics     = ['l1','l2','chi2']\n",
    "masks       = ['letters']\n",
    "normalize   = 'global'\n",
    "decay       = ('exp', 0.7)\n",
    "\n",
    "corpus = load_folder_corpus(corpus_root)\n",
    "len(corpus), list(corpus.keys())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "results = run_grid(corpus, horizons=horizons, metrics=metrics, masks=masks,\n",
    "                   normalize=normalize, decay=decay)\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values(['mask','metric','horizon']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_accuracy(df, title):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for metric in sorted(df['metric'].unique()):\n",
    "        d = df[df['metric']==metric].sort_values('horizon')\n",
    "        plt.plot(d['horizon'], d['loocv_acc']*100, label=metric)\n",
    "    plt.xlabel('Horizon h'); plt.ylabel('LOOCV accuracy, %'); plt.title(title)\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_throughput(df, title):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for metric in sorted(df['metric'].unique()):\n",
    "        d = df[df['metric']==metric].sort_values('horizon')\n",
    "        plt.plot(d['horizon'], d['throughput_MBps'], label=metric)\n",
    "    plt.xlabel('Horizon h'); plt.ylabel('Throughput (MB/s)'); plt.title(title)\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "for mask in sorted(df['mask'].unique()):\n",
    "    dfx = df[df['mask']==mask]\n",
    "    plot_accuracy(dfx, f'Accuracy vs Horizon (mask={mask})')\n",
    "    plot_throughput(dfx, f'Throughput vs Horizon (mask={mask})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}